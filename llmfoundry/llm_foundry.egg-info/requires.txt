mosaicml[libcloud,mlflow,wandb]<0.16,>=0.15.0
accelerate<0.21,>=0.20
transformers<4.32,>=4.31
mosaicml-streaming<0.6,>=0.5.1
torch<=2.0.1,>=1.13.1
datasets==2.10.1
sentencepiece==0.1.97
einops==0.5.0
omegaconf<3,>=2.2.3
slack-sdk<4
mosaicml-cli<1,>=0.3
onnx==1.14.0
onnxruntime==1.15.1
cmake<=3.26.3,>=3.25.0

[all]
bitsandbytes==0.39.1
flash-attn==v1.0.3.post0
toml<0.11,>=0.10.2
hf_transfer==0.1.3
loralib==0.1.1
peft==0.4.0
xentropy-cuda-lib@ git+https://github.com/HazyResearch/flash-attention.git@v1.0.3#subdirectory=csrc/xentropy
pyright==1.1.256
scipy<=1.11.0,>=1.10.0
pytest_codeblocks<0.17,>=0.16.1
pytest<8,>=7.2.1
pytest-cov<5,>=4
packaging<23,>=21
mosaicml[tensorboard]<0.16,>=0.15.0
pre-commit<3,>=2.18.1

[dev]
pre-commit<3,>=2.18.1
pytest<8,>=7.2.1
pytest_codeblocks<0.17,>=0.16.1
pytest-cov<5,>=4
pyright==1.1.256
toml<0.11,>=0.10.2
packaging<23,>=21
hf_transfer==0.1.3

[gpu]
flash-attn==v1.0.3.post0
xentropy-cuda-lib@ git+https://github.com/HazyResearch/flash-attention.git@v1.0.3#subdirectory=csrc/xentropy

[peft]
loralib==0.1.1
bitsandbytes==0.39.1
scipy<=1.11.0,>=1.10.0
peft==0.4.0

[tensorboard]
mosaicml[tensorboard]<0.16,>=0.15.0
